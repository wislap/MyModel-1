# 多模态工具 Router 模型结构设计报告

**（文本 / 语音 → 统一语义空间 → 工具选择）**

---

## 1. 任务背景与目标

### 1.1 任务背景

本项目的核心任务是 **工具（插件）路由（Router）**，即：

> 在实时对话（文本或语音）场景中，  
> 根据用户当前意图，从一组工具 / 插件中判断：  
> - 是否需要调用工具  
> - 调用哪个工具（或 Top-k）

**特点：**
- 用户表达自然口语，不直接说工具名
- 工具数量有限（~100–200），可接受新增 / 重训
- 数据集很小，无法依赖大量自有标注
- 未来包含 **实时语音聊天**

---

### 1.2 设计目标

1. **统一语义空间**  
   文本、语音都能映射到同一向量空间

2. **小数据可训练 / 可迁移**  
   能利用现成数据集（SNIPS / ATIS / MultiWOZ）

3. **实时性友好**  
   Router 不依赖完整 ASR 结果

4. **结构清晰、可扩展**  
   方便未来加新工具、新模态

---

## 2. 整体模型架构总览

### 2.1 架构总图（逻辑）

#### 文本输入流程

```
┌──────────────┐
│  文本输入    │
└──────┬───────┘
       │ tokenizer + embedding
       ▼
┌──────────────────────┐
│   Text Encoder       │
│   (Mamba-based)      │
└─────────┬────────────┘
          │
          │ h ∈ ℝ^D （语义向量）
          │
┌─────────▼────────────┐
│   统一语义空间        │
└─────────┬────────────┘
          │
┌─────────▼────────────┐
│  Router / Tool Match │
│  (相似度 / 分类)      │
└─────────┬────────────┘
          │
    工具置信度 / Top-k
```

#### 语音输入流程（未来扩展）

```
┌──────────────┐
│  语音输入    │
└──────┬───────┘
       │ Speech Encoder
       ▼
┌──────────────────────┐
│   Speech Encoder     │
│  (Whisper/Wav2Vec)   │
└─────────┬────────────┘
          │
          ▼
    同一语义空间 ℝ^D
```

---

## 3. 输入与核心张量定义

### 3.1 三个核心维度（必须理解）

| 符号 | 含义 | 在本项目中的解释 |
|------|------|------------------|
| **B** | Batch size | 一次并行处理的样本数 |
| **T** | Sequence length | token 序列长度（padding 后） |
| **D** | Hidden dimension | 每个 token / 语句的语义维度 |

---

### 3.2 文本输入

- `input_ids`：`[B, T]`
- `attention_mask`：`[B, T]`
- `token_embedding` 后：
  - `x_text`：`[B, T, D]`

---

### 3.3 语音输入（可选）

- 原始波形 / mel 特征
- Speech Encoder 输出：
  - `x_audio`：`[B, T_audio, D]`
- pooling 后：
  - `h_audio`：`[B, D]`

---

## 4. Text Encoder：基于 Mamba 的序列建模

### 4.1 为什么选择 Mamba

- **线性时间复杂度** O(T)
- **强顺序建模能力**（递推状态）
- **小模型、小数据更稳定**
- 比 Transformer 更适合长上下文 Router

---

### 4.2 Mamba Encoder 输入 / 输出

**输入：**
```
x ∈ ℝ[B, T, D]
```

**输出（序列）：**
```
y ∈ ℝ[B, T, D]
```

**Pooling 后输出（句向量）：**
```
h ∈ ℝ[B, D]
```

---

### 4.3 Mamba Block 内部计算流程（概念）

每一层 Mamba Block 逻辑为：

1. **RMSNorm**  
   稳定数值分布

2. **线性映射 + 门控**
   - 内容流
   - gate（控制信息通过）

3. **Depthwise 1D 卷积**
   - 局部时间混合（短期上下文）

4. **Selective State Space Model（核心）**
   - 维护随时间递推的状态 `s_t`
   - 动态参数 `a_t, b_t, c_t`
   - 公式：
     ```
     s_t = s_{t-1} ⊙ a_t + b_t ⊙ x_t
     y_t = c_t ⊙ s_t
     ```

5. **状态 → 通道映射**
6. **残差连接**

---

### 4.4 Pooling 策略

采用 **Last-token pooling**：

```
h = y[b, last_valid_index, :]
```

**原因：**
- 滑动对话中，末尾信息最重要
- 对 Router 决策更稳定

---

## 5. Tool 表示与 Router 设计

### 5.1 工具表示方式

每个工具用一段 **文本描述 / JSON 卡片** 表示：

```json
{
  "name": "工具名称",
  "description": "工具描述",
  "required_params": ["参数1", "参数2"],
  "examples": ["示例1", "示例2"]
}
```

通过 **同一个 Text Encoder** 编码为：

```
u_i ∈ ℝ^D
```

所有工具构成 **工具向量库**：

```
U = [u_1, u_2, ..., u_N] ∈ ℝ[N, D]
```

---

### 5.2 Router 核心计算

#### 两塔（语义匹配）形式：

```
score_i = h · u_i
```

- `h`：当前对话语义
- `u_i`：第 i 个工具语义
- 输出：
  - `scores ∈ ℝ^N`
  - Top-k 工具候选

#### 或分类形式（可选）：

```
logits = Linear(h) ∈ ℝ^N
```

---

## 6. 语音 Encoder 与多模态对齐

### 6.1 为什么需要语音 Encoder

- 实时语音中包含：
  - 语气
  - 停顿
  - 未完成句
- Router 可在 ASR 完成前提前预测工具

---

### 6.2 语音 Encoder 角色

Speech Encoder 的目标不是"转文字"，而是：

> **直接输出语义向量**

```
audio → Speech Encoder → h_audio ∈ ℝ^D
```

---

### 6.3 语音 / 文本对齐方式

#### 蒸馏（推荐，最稳）

- 冻结 Text Encoder
- 训练 Speech Encoder
- 目标：
  ```
  h_audio ≈ h_text
  ```

#### 对比学习（CLIP-style）

- 同一句话的语音 / 文本靠近
- 不同句子拉远

---

### 6.4 Router 的模态无关性

一旦对齐完成：

```python
Router(h)  # h 可来自 text 或 audio
```

Router 不关心输入模态。

---

## 7. 训练流程总览

### 7.1 阶段一：文本语义训练（核心）

- **数据集：**
  - SNIPS
  - ATIS
  - MultiWOZ
- **目标：**
  - 学会「自然语言 → 意图 / 工具语义」

---

### 7.2 阶段二：工具向量构建

- 编码所有工具描述
- 构建工具向量库

---

### 7.3 阶段三：语音对齐（可选）

- **数据：**
  - LibriSpeech / Common Voice
- **目标：**
  - Speech → 同一语义空间

---

## 8. 为什么这个架构是合理的

### 8.1 对小数据友好

- 语言能力来自公开数据
- 工具能力来自文本描述

### 8.2 对实时场景友好

- Router 不依赖完整 ASR
- 可中途预测

### 8.3 对未来扩展友好

- 新工具：只加向量
- 新模态：只加 encoder

---

## 9. 关键设计总结（一句话版）

> **本模型将"理解用户在想什么"和"工具能做什么"解耦，  
> 通过 Mamba 建模上下文，通过统一语义向量空间完成 Router 决策，  
> 天然支持文本与语音的实时、多模态工具调用。**

---

## 附录：技术细节

### A. 数据流示例

**文本输入：**
```
用户输入: "Share my location with Hillary's sister"
  ↓ tokenizer
input_ids: [151643, 1234, 5678, ...]
  ↓ embedding
x_text: [B, T, D]
  ↓ Mamba Encoder
h: [B, D]
  ↓ Router
scores: [N] → Top-k tools
```

**工具匹配：**
```
工具描述: "Share current location tool"
  ↓ Text Encoder
u_i: [D]
  ↓ 相似度计算
score_i = h · u_i
```

---

### B. 实现要点

1. **Token Embedding**
   - 使用 `len(tokenizer)` 而非 `vocab_size`
   - 支持 attention_mask
   - 不允许自动扩容（确保可复现）

2. **Checkpoint 管理**
   - 自动保存/恢复训练状态
   - 包含模型、优化器、epoch、step

3. **精度控制**
   - 支持 fp32 / amp-fp16 / amp-bf16
   - 混合精度训练优化

4. **数据集加载**
   - 支持 SNIPS / ATIS 等意图识别数据集
   - 可配置训练样本数量

---
